# -*- coding: utf-8 -*-
"""Acctividad6

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1evQgpp46T4MouFFYJhTM8V_EITKC6sgO
"""

# Import required libraries
import pandas as pd
import numpy as np
from google.colab import files
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt

# List of file names to upload
file_names = ['BDX1MIN', 'BDX3MIN', 'BAC1MIN', 'BAC3MIN', 'AMZN1MIN', 'AMZN3MIN']

# Dictionary to store DataFrames
dfs = {}

# Upload Excel files
for file in file_names:
    print(f"Please upload {file}.xlsx")
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    dfs[file] = pd.read_excel(filename)
    print(f"\n{file} DataFrame columns:", list(dfs[file].columns))

# Ask user for the closing price column name
close_column = input("Please enter the column name containing closing prices: ")

# Extract closing prices and ensure same length
close_series = {}
min_length = float('inf')

# Get minimum length across all series
for file in file_names:
    try:
        close_series[file] = dfs[file][close_column]
        min_length = min(min_length, len(close_series[file]))
    except KeyError:
        print(f"Error: Column '{close_column}' not found in {file} DataFrame")
        print("Please check the column names and try again")
        raise

# Truncate all series to the minimum length
for file in file_names:
    close_series[file] = close_series[file][:min_length]

# Function for unit root tests
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")

    # ADF Test
    adf_result = adfuller(series)
    print("ADF Test:")
    print(f'ADF Statistic: {adf_result[0]:.4f}')
    print(f'p-value: {adf_result[1]:.4f}')
    print(f'Critical Values: {adf_result[4]}')

    # KPSS Test
    kpss_result = kpss(series)
    print("\nKPSS Test:")
    print(f'KPSS Statistic: {kpss_result[0]:.4f}')
    print(f'p-value: {kpss_result[1]:.4f}')
    print(f'Critical Values: {kpss_result[3]}')

# Perform unit root tests for each series
for file in file_names:
    unit_root_tests(close_series[file], file)

# Difference the series
diff_series = {file: close_series[file].diff().dropna() for file in file_names}

# Function to find best ARMA model (using ARIMA with d=0)
def find_best_arma(series, name, max_p=3, max_q=3):
    best_aic = float('inf')
    best_order = None

    for p in range(max_p + 1):
        for q in range(max_q + 1):
            try:
                model = ARIMA(series, order=(p, 0, q))
                results = model.fit()
                if results.aic < best_aic:
                    best_aic = results.aic
                    best_order = (p, 0, q)
            except:
                continue

    print(f"\nBest ARMA model for {name}:")
    print(f"Order: {best_order}")
    print(f"AIC: {best_aic:.2f}")

    best_model = ARIMA(series, order=best_order).fit()
    return best_model

# Fit ARMA models for differenced series
arma_models = {}
for file in file_names:
    arma_models[file] = find_best_arma(diff_series[file], file)

# Cointegration test
def cointegration_test(df):
    result = coint_johansen(df, det_order=0, k_ar_diff=1)
    print("\nJohansen Cointegration Test:")
    print(f"Trace statistic: {result.lr1}")
    print(f"Critical values (90%, 95%, 99%): {result.cvt}")

    for i in range(len(result.lr1)):
        if result.lr1[i] > result.cvt[i, 1]:  # 95% critical value
            print(f"r = {i}: Cointegration exists at 95% confidence level")
        else:
            print(f"r = {i}: No cointegration at 95% confidence level")

# Prepare data for cointegration
coint_df = pd.DataFrame({file: close_series[file] for file in file_names}).dropna()

# Run cointegration test
cointegration_test(coint_df)

# Plot the original series
plt.figure(figsize=(12, 6))
for file in file_names:
    plt.plot(close_series[file], label=file)
plt.title('Closing Prices of All Series')
plt.legend()
plt.show()

# Plot the differenced series
plt.figure(figsize=(12, 6))
for file in file_names:
    plt.plot(diff_series[file], label=f'{file} Diff')
plt.title('Differenced Series')
plt.legend()
plt.show()

# Plot all 1-minute closing prices
plt.figure(figsize=(12, 6))
for file in ['BDX1MIN', 'BAC1MIN', 'AMZN1MIN']:
    plt.plot(close_series[file], label=file)
plt.title('1-Minute Closing Prices (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Plot all 3-minute closing prices
plt.figure(figsize=(12, 6))
for file in ['BDX3MIN', 'BAC3MIN', 'AMZN3MIN']:
    plt.plot(close_series[file], label=file)
plt.title('3-Minute Closing Prices (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Plot all 1-minute differenced series
plt.figure(figsize=(12, 6))
for file in ['BDX1MIN', 'BAC1MIN', 'AMZN1MIN']:
    plt.plot(diff_series[file], label=f'{file} Diff')
plt.title('1-Minute Differenced Series (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Plot all 3-minute differenced series
plt.figure(figsize=(12, 6))
for file in ['BDX3MIN', 'BAC3MIN', 'AMZN3MIN']:
    plt.plot(diff_series[file], label=f'{file} Diff')
plt.title('3-Minute Differenced Series (BDX, BAC, AMZN)')
plt.legend()
plt.show()

"""BDX1MIN
- ADF p-valor: 0.2090 → No se rechaza H₀ ⇒ tiene raíz unitaria
- KPSS p-valor: 0.0100 → Se rechaza H₀ ⇒ no es estacionaria
- Conclusión: La serie tiene raíz unitaria y no es estacionaria

BDX3MIN
- ADF p-valor: 0.1132 → No se rechaza H₀ ⇒ tiene raíz unitaria
- KPSS p-valor: 0.0100 → Se rechaza H₀ ⇒ no es estacionaria
- Conclusión: La serie tiene raíz unitaria y no es estacionaria
BAC1MIN
- ADF p-valor: 0.5708 → No se rechaza H₀ ⇒ tiene raíz unitaria
- KPSS p-valor: 0.0100 → Se rechaza H₀ ⇒ no es estacionaria
- Conclusión: La serie tiene raíz unitaria y no es estacionaria

BAC3MIN
- ADF p-valor: 0.6571 → No se rechaza H₀ ⇒ tiene raíz unitaria
- KPSS p-valor: 0.0100 → Se rechaza H₀ ⇒ no es estacionaria
- Conclusión: La serie tiene raíz unitaria y no es estacionaria

AMZN1MIN
- ADF p-valor: 0.8926 → No se rechaza H₀ ⇒ tiene raíz unitaria
- KPSS p-valor: 0.0100 → Se rechaza H₀ ⇒ no es estacionaria
- Conclusión: La serie tiene raíz unitaria y no es estacionaria

AMZN3MIN
- ADF p-valor: 0.8143 → No se rechaza H₀ ⇒ tiene raíz unitaria
- KPSS p-valor: 0.0100 → Se rechaza H₀ ⇒ no es estacionaria
- Conclusión: La serie tiene raíz unitaria y no es estacionaria


Cointegration:
- No existe una relación de equilibrio a largo plazo entre las series. Aunque todas las series sean no estacionarias, sus movimientos no están sincronizados ni ligados entre sí a largo plazo. En términos prácticos, estas series pueden moverse independientemente unas de otras sin que sus desviaciones se corrijan naturalmente con el tiempo.
"""

# Import required libraries
import pandas as pd
import numpy as np
from google.colab import files
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt

# List of file names to upload
file_names = ['BDX1MIN', 'BDX3MIN', 'BAC1MIN', 'BAC3MIN', 'AMZN1MIN', 'AMZN3MIN']

# Dictionary to store DataFrames
dfs = {}

# Upload Excel files
for file in file_names:
    print(f"Please upload {file}.xlsx")
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    dfs[file] = pd.read_excel(filename)
    print(f"\n{file} DataFrame columns:", list(dfs[file].columns))

# Ask user for the closing price column name
close_column = input("Please enter the column name containing closing prices: ")

# Extract closing prices and ensure same length
close_series = {}
min_length = float('inf')

# Get minimum length across all series
for file in file_names:
    try:
        close_series[file] = dfs[file][close_column]
        min_length = min(min_length, len(close_series[file]))
    except KeyError:
        print(f"Error: Column '{close_column}' not found in {file} DataFrame")
        print("Please check the column names and try again")
        raise

# Truncate all series to the minimum length
for file in file_names:
    close_series[file] = close_series[file][:min_length]

# Function for unit root tests
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")

    # ADF Test
    adf_result = adfuller(series)
    print("ADF Test:")
    print(f'ADF Statistic: {adf_result[0]:.4f}')
    print(f'p-value: {adf_result[1]:.4f}')
    print(f'Critical Values: {adf_result[4]}')

    # KPSS Test
    kpss_result = kpss(series)
    print("\nKPSS Test:")
    print(f'KPSS Statistic: {kpss_result[0]:.4f}')
    print(f'p-value: {kpss_result[1]:.4f}')
    print(f'Critical Values: {kpss_result[3]}')

# Perform unit root tests for each series
for file in file_names:
    unit_root_tests(close_series[file], file)

# Cointegration test
def cointegration_test(df):
    result = coint_johansen(df, det_order=0, k_ar_diff=1)
    print("\nJohansen Cointegration Test:")
    print(f"Trace statistic: {result.lr1}")
    print(f"Critical values (90%, 95%, 99%): {result.cvt}")

    for i in range(len(result.lr1)):
        if result.lr1[i] > result.cvt[i, 1]:
            print(f"r = {i}: Cointegration exists at 95% confidence level")
        else:
            print(f"r = {i}: No cointegration at 95% confidence level")

# Prepare data for cointegration
coint_df = pd.DataFrame({file: close_series[file] for file in file_names}).dropna()
cointegration_test(coint_df)

# Function to find best ARIMA model
def find_best_arima(series, name, max_p=3, max_d=2, max_q=3):
    best_aic = float('inf')
    best_order = None

    for p in range(max_p + 1):
        for d in range(max_d + 1):
            for q in range(max_q + 1):
                try:
                    model = ARIMA(series, order=(p, d, q))
                    results = model.fit()
                    if results.aic < best_aic:
                        best_aic = results.aic
                        best_order = (p, d, q)
                except:
                    continue

    print(f"\nBest ARIMA model for {name}:")
    print(f"Order: {best_order}")
    print(f"AIC: {best_aic:.2f}")
    return best_order

# Find and fit best ARIMA models
arima_orders = {}
arima_models = {}
for file in file_names:
    arima_orders[file] = find_best_arima(close_series[file], file)
    arima_models[file] = ARIMA(close_series[file], order=arima_orders[file]).fit()

# Forecast next 30 periods
forecast_steps = 30
forecasts = {}
for file in file_names:
    forecasts[file] = arima_models[file].forecast(steps=forecast_steps)

# Create forecast index (assuming time-series data)
last_index = min_length - 1
forecast_index = range(last_index + 1, last_index + 1 + forecast_steps)

# Plot all 1-minute closing prices with forecasts
plt.figure(figsize=(12, 6))
for file in ['BDX1MIN', 'BAC1MIN', 'AMZN1MIN']:
    plt.plot(close_series[file], label=f'{file} Historical')
    plt.plot(forecast_index, forecasts[file], label=f'{file} Forecast', linestyle='--')
plt.title('1-Minute Closing Prices with Forecasts (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Plot all 3-minute closing prices with forecasts
plt.figure(figsize=(12, 6))
for file in ['BDX3MIN', 'BAC3MIN', 'AMZN3MIN']:
    plt.plot(close_series[file], label=f'{file} Historical')
    plt.plot(forecast_index, forecasts[file], label=f'{file} Forecast', linestyle='--')
plt.title('3-Minute Closing Prices with Forecasts (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Plot detailed forecast with confidence intervals
def plot_forecast(model, series, name, steps=30):
    forecast_obj = model.get_forecast(steps=steps)
    forecast = forecast_obj.predicted_mean
    conf_int = forecast_obj.conf_int()

    forecast_index = range(len(series), len(series) + steps)

    plt.figure(figsize=(12, 6))
    plt.plot(series, label=f'{name} Historical')
    plt.plot(forecast_index, forecast, label='Forecast', color='red')
    plt.fill_between(forecast_index,
                    conf_int.iloc[:, 0],
                    conf_int.iloc[:, 1],
                    color='pink',
                    alpha=0.3,
                    label='95% Confidence Interval')
    plt.title(f'{name} Price Forecast')
    plt.legend()
    plt.show()

# Generate detailed forecast plots for each series
for file in file_names:
    plot_forecast(arima_models[file], close_series[file], file)

# Print forecast values for the next 5 periods
for file in file_names:
    print(f"\n{file} Forecast Values (next 5 periods):")
    print(forecasts[file][:5])

"""Interpretación de los pronósticos
- Para la serie BDX con frecuencia de 1 minuto, el modelo pronostica que el precio se mantendrá estable alrededor de 173 en los próximos cinco periodos, con leves fluctuaciones. Esto sugiere que el modelo capta cierta inercia en el comportamiento del activo, sin anticipar cambios bruscos.En la serie BDX con frecuencia de 3 minutos, se observa un patrón similar, aunque con una ligera variación entre los valores pronosticados, que se mueven en un rango cercano a 171. Este comportamiento puede deberse a que la mayor agregación temporal suaviza el ruido, permitiendo ligeras oscilaciones alrededor de un valor central.

- Para BAC en 1 minuto, el modelo estima una secuencia prácticamente constante cercana a 43.65, lo que indica que la serie fue considerada estable en los datos más recientes y que el modelo no espera cambios significativos a corto plazo. En la frecuencia de 3 minutos, esta estabilidad es aún más marcada: el modelo predice exactamente el mismo valor en los cinco periodos futuros. Este tipo de pronóstico suele ser resultado de un modelo que no encuentra dinámica significativa en los datos o que fue ajustado de manera muy conservadora.

- En el caso de AMZN con datos de 1 minuto, el modelo predice una leve subida seguida de una corrección, con valores entre 204.20 y 204.28, lo que indica una pequeña variabilidad en la dinámica del precio, aunque el rango de cambio sigue siendo muy reducido. Por el contrario, en la serie AMZN con frecuencia de 3 minutos, el modelo proyecta un valor completamente plano de 200.33 durante todos los periodos pronosticados, lo que sugiere una visión neutral del comportamiento futuro del activo.

Conclusión general
Los pronósticos generados para todas las series presentan un alto grado de estabilidad y poca variación, lo cual es coherente con el comportamiento típico de series de alta frecuencia que siguen un camino aleatorio. Estas predicciones reflejan que los modelos utilizados, posiblemente de tipo ARIMA o similares, no detectaron tendencias ni estacionalidades significativas en los datos recientes. Por tanto, las proyecciones a corto plazo tienden a mantenerse cercanas a los últimos valores observados. Este comportamiento es común en activos financieros líquidos, donde los precios incorporan rápidamente la información disponible y se vuelven difíciles de predecir más allá del muy corto plazo.
"""

# Import required libraries
import pandas as pd
import numpy as np
from google.colab import files
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, kpss
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.vector_ar.vecm import coint_johansen
import matplotlib.pyplot as plt

# List of file names to upload
file_names = ['BDX1MIN', 'BDX3MIN', 'BAC1MIN', 'BAC3MIN', 'AMZN1MIN', 'AMZN3MIN']

# Dictionary to store DataFrames
dfs = {}

# Upload Excel files
for file in file_names:
    print(f"Please upload {file}.xlsx")
    uploaded = files.upload()
    filename = list(uploaded.keys())[0]
    dfs[file] = pd.read_excel(filename)
    print(f"\n{file} DataFrame columns:", list(dfs[file].columns))

# Ask user for the closing price column name
close_column = input("Please enter the column name containing closing prices: ")

# Extract closing prices and ensure same length
close_series = {}
min_length = float('inf')

# Get minimum length across all series
for file in file_names:
    try:
        close_series[file] = dfs[file][close_column]
        min_length = min(min_length, len(close_series[file]))
    except KeyError:
        print(f"Error: Column '{close_column}' not found in {file} DataFrame")
        print("Please check the column names and try again")
        raise

# Truncate all series to the minimum length
for file in file_names:
    close_series[file] = close_series[file][:min_length]

# Function for unit root tests with interpretation
def unit_root_tests(series, name):
    print(f"\nUnit Root Tests for {name}:")

    # ADF Test
    adf_result = adfuller(series)
    print("ADF Test:")
    print(f'ADF Statistic: {adf_result[0]:.4f}')
    print(f'p-value: {adf_result[1]:.4f}')
    print(f'Critical Values: {adf_result[4]}')
    print("Interpretation:")
    if adf_result[1] < 0.05:
        print(f"  - p-value < 0.05: Reject null hypothesis - {name} is stationary")
    else:
        print(f"  - p-value >= 0.05: Fail to reject null - {name} may be non-stationary")

    # KPSS Test
    kpss_result = kpss(series)
    print("\nKPSS Test:")
    print(f'KPSS Statistic: {kpss_result[0]:.4f}')
    print(f'p-value: {kpss_result[1]:.4f}')
    print(f'Critical Values: {kpss_result[3]}')
    print("Interpretation:")
    if kpss_result[1] < 0.05:
        print(f"  - p-value < 0.05: Reject null hypothesis - {name} is non-stationary")
    else:
        print(f"  - p-value >= 0.05: Fail to reject null - {name} may be stationary")

# Perform unit root tests for each series
for file in file_names:
    unit_root_tests(close_series[file], file)

# Cointegration test with interpretation
def cointegration_test(df):
    result = coint_johansen(df, det_order=0, k_ar_diff=1)
    print("\nJohansen Cointegration Test:")
    print(f"Trace statistic: {result.lr1}")
    print(f"Critical values (90%, 95%, 99%): {result.cvt}")
    print("Interpretation:")
    for i in range(len(result.lr1)):
        if result.lr1[i] > result.cvt[i, 1]:
            print(f"  - r = {i}: Cointegration exists at 95% confidence level")
            print(f"    Trace statistic ({result.lr1[i]:.2f}) > 95% critical value ({result.cvt[i, 1]:.2f})")
        else:
            print(f"  - r = {i}: No cointegration at 95% confidence level")
            print(f"    Trace statistic ({result.lr1[i]:.2f}) <= 95% critical value ({result.cvt[i, 1]:.2f})")
    if result.lr1[0] > result.cvt[0, 1]:
        print("Conclusion: The series are cointegrated - they share a long-run equilibrium relationship")
    else:
        print("Conclusion: No evidence of cointegration among the series")

# Prepare data for cointegration
coint_df = pd.DataFrame({file: close_series[file] for file in file_names}).dropna()
cointegration_test(coint_df)

# Function to find best ARIMA model with interpretation
def find_best_arima(series, name, max_p=3, max_d=2, max_q=3):
    best_aic = float('inf')
    best_order = None

    for p in range(max_p + 1):
        for d in range(max_d + 1):
            for q in range(max_q + 1):
                try:
                    model = ARIMA(series, order=(p, d, q))
                    results = model.fit()
                    if results.aic < best_aic:
                        best_aic = results.aic
                        best_order = (p, d, q)
                except:
                    continue

    print(f"\nBest ARIMA model for {name}:")
    print(f"Order: {best_order}")
    print(f"AIC: {best_aic:.2f}")
    print("Interpretation:")
    print(f"  - p={best_order[0]}: {best_order[0]} autoregressive term(s)")
    print(f"  - d={best_order[1]}: {best_order[1]} difference(s) needed for stationarity")
    print(f"  - q={best_order[2]}: {best_order[2]} moving average term(s)")
    return best_order

# Find and fit best ARIMA models
arima_orders = {}
arima_models = {}
for file in file_names:
    arima_orders[file] = find_best_arima(close_series[file], file)
    arima_models[file] = ARIMA(close_series[file], order=arima_orders[file]).fit()

# Forecast next 30 periods
forecast_steps = 30
forecasts = {}
for file in file_names:
    forecasts[file] = arima_models[file].forecast(steps=forecast_steps)

# Create forecast index
last_index = min_length - 1
forecast_index = range(last_index + 1, last_index + 1 + forecast_steps)

# Plot all 1-minute closing prices with forecasts
plt.figure(figsize=(12, 6))
for file in ['BDX1MIN', 'BAC1MIN', 'AMZN1MIN']:
    plt.plot(close_series[file], label=f'{file} Historical')
    plt.plot(forecast_index, forecasts[file], label=f'{file} Forecast', linestyle='--')
plt.title('1-Minute Closing Prices with Forecasts (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Plot all 3-minute closing prices with forecasts
plt.figure(figsize=(12, 6))
for file in ['BDX3MIN', 'BAC3MIN', 'AMZN3MIN']:
    plt.plot(close_series[file], label=f'{file} Historical')
    plt.plot(forecast_index, forecasts[file], label=f'{file} Forecast', linestyle='--')
plt.title('3-Minute Closing Prices with Forecasts (BDX, BAC, AMZN)')
plt.legend()
plt.show()

# Detailed forecast plot with confidence intervals and interpretation
def plot_forecast(model, series, name, steps=30):
    forecast_obj = model.get_forecast(steps=steps)
    forecast = forecast_obj.predicted_mean
    conf_int = forecast_obj.conf_int()

    forecast_index = range(len(series), len(series) + steps)

    plt.figure(figsize=(12, 6))
    plt.plot(series, label=f'{name} Historical')
    plt.plot(forecast_index, forecast, label='Forecast', color='red')
    plt.fill_between(forecast_index,
                    conf_int.iloc[:, 0],
                    conf_int.iloc[:, 1],
                    color='pink',
                    alpha=0.3,
                    label='95% Confidence Interval')
    plt.title(f'{name} Price Forecast')
    plt.legend()
    plt.show()

    # Forecast interpretation
    last_value = series.iloc[-1]
    mean_forecast = forecast.mean()
    print(f"\nForecast Interpretation for {name}:")
    print(f"Last observed value: {last_value:.2f}")
    print(f"Average forecast value: {mean_forecast:.2f}")
    print(f"Forecast change: {mean_forecast - last_value:.2f}")
    if mean_forecast > last_value:
        print("Trend: Upward forecast trend")
    elif mean_forecast < last_value:
        print("Trend: Downward forecast trend")
    else:
        print("Trend: Flat forecast trend")
    print(f"95% CI range at period {steps}: [{conf_int.iloc[-1, 0]:.2f}, {conf_int.iloc[-1, 1]:.2f}]")

# Generate detailed forecast plots and interpretations for each series
for file in file_names:
    plot_forecast(arima_models[file], close_series[file], file)

# Print forecast values for the next 5 periods
for file in file_names:
    print(f"\n{file} Forecast Values (next 5 periods):")
    print(forecasts[file][:5])

"""1. Raíz unitaria y estacionariedad
Se aplicaron dos pruebas estadísticas a las series de precios de BDX, BAC y AMZN, tanto en frecuencia de 1 minuto como de 3 minutos: la prueba ADF y la prueba KPSS.

La prueba ADF no rechaza la hipótesis de que las series tienen raíz unitaria, es decir, no son estacionarias.

La prueba KPSS rechaza la hipótesis de que las series sean estacionarias.

Por lo tanto, todas las series analizadas son no estacionarias, lo cual es común en precios de acciones, ya que tienden a moverse sin volver a un nivel promedio fijo (siguen un camino aleatorio).

2. Cointegración
Se utilizó el test de Johansen para analizar si las series están relacionadas a largo plazo, es decir, si existe cointegración.

En todos los niveles (r = 0 a r = 5), el estadístico fue menor que el valor crítico.

Esto significa que no hay evidencia de cointegración entre las series.

En resumen, las series no están ligadas entre sí en el largo plazo y se mueven de forma independiente.

3. Pronósticos
Se generaron pronósticos a cinco periodos para cada serie:

BDX1MIN muestra una ligera tendencia a la baja.

BDX3MIN presenta una leve tendencia al alza.

BAC1MIN y BAC3MIN se mantienen prácticamente constantes, con cambios mínimos.

AMZN1MIN muestra una pequeña alza.

AMZN3MIN se mantiene estable, sin cambios relevantes.

En general, los modelos pronostican que los precios seguirán cerca de sus niveles actuales. Esto es normal en series de alta frecuencia, donde los cambios suelen ser muy pequeños a corto plazo.
"""